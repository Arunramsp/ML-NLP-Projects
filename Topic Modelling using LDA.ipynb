{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "cvectorizer= CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\" I love cooking\",\"I have prepared a cake today\",\"he is now going to a new place\",\"he will learn cooking there\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x16 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 18 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we will just call the fit_transform for cvectorizer where it converts strings into numeric representation. \n",
    "cvz = cvectorizer.fit_transform(corpus)\n",
    "cvz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cake',\n",
       " 'cooking',\n",
       " 'going',\n",
       " 'have',\n",
       " 'he',\n",
       " 'is',\n",
       " 'learn',\n",
       " 'love',\n",
       " 'new',\n",
       " 'now',\n",
       " 'place',\n",
       " 'prepared',\n",
       " 'there',\n",
       " 'to',\n",
       " 'today',\n",
       " 'will']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = cvectorizer.get_feature_names()\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_comp - represents no of topics to be defined. max_iter - no of iterations model should run. \n",
    "lda_model = LatentDirichletAllocation(n_components = 3, max_iter = 20,random_state = 20 )\n",
    "X_topics = lda_model.fit_transform(cvz)\n",
    "topic_words = lda_model.components_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1 [['going' 'is' 'new' 'now' 'place' 'to' 'learn' 'there' 'will' 'he'\n",
      "  'love' 'cooking' 'cake' 'have' 'prepared' 'today']\n",
      " ['cake' 'have' 'prepared' 'today' 'learn' 'there' 'will' 'cooking'\n",
      "  'love' 'he' 'going' 'is' 'new' 'now' 'place' 'to']\n",
      " ['going' 'is' 'new' 'now' 'place' 'to' 'cake' 'have' 'prepared' 'today'\n",
      "  'love' 'learn' 'there' 'will' 'he' 'cooking']]\n",
      "Topic 2 [['learn' 'will' 'cake' 'love' 'today' 'cooking' 'prepared' 'place'\n",
      "  'going' 'have' 'he' 'new' 'there' 'is' 'now' 'to']\n",
      " ['cake' 'love' 'place' 'cooking' 'now' 'prepared' 'he' 'new' 'there'\n",
      "  'to' 'today' 'going' 'is' 'will' 'have' 'learn']\n",
      " ['there' 'prepared' 'cake' 'to' 'now' 'cooking' 'learn' 'place' 'going'\n",
      "  'have' 'he' 'today' 'love' 'is' 'will' 'new']]\n",
      "Topic 3 [['going' 'is' 'new' 'now' 'place' 'to' 'learn' 'there' 'will' 'he'\n",
      "  'love' 'cooking' 'cake' 'have' 'prepared' 'today']\n",
      " ['cake' 'have' 'prepared' 'today' 'learn' 'there' 'will' 'cooking'\n",
      "  'love' 'he' 'going' 'is' 'new' 'now' 'place' 'to']\n",
      " ['going' 'is' 'new' 'now' 'place' 'to' 'cake' 'have' 'prepared' 'today'\n",
      "  'love' 'learn' 'there' 'will' 'he' 'cooking']]\n"
     ]
    }
   ],
   "source": [
    "n_top_words = 4\n",
    "for i , topic_dist in enumerate(topic_words):\n",
    "    sorted_topic_dist =  np.argsort(topic_words)\n",
    "    topic_words = np.array(vocab)[sorted_topic_dist]\n",
    "    topic_words = topic_words[:-n_top_words:-1]\n",
    "    print(\"Topic\", str(i+1), topic_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1  -- Topic: 1\n",
      "Document 2  -- Topic: 2\n",
      "Document 3  -- Topic: 1\n",
      "Document 4  -- Topic: 0\n"
     ]
    }
   ],
   "source": [
    "doc_topic = lda_model.transform(cvz)\n",
    "for n in range(doc_topic.shape[0]): #no of rows present in topic till the end\n",
    "    topic_doc = doc_topic[n].argmax()\n",
    "    print(\"Document\", n+1, \" -- Topic:\", topic_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
